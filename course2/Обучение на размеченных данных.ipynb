{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стохастический градиентный спуск (SGD) \n",
    "- градиенты считаются не по всей выборке, а только по одному объекту\n",
    "- позволяет не хранить всю выборку в памяти\n",
    "- кривая обучения (график зависимости ошибки на выборке от числа итераций градиентного спуска) для обычного спуска выглядит глаже, чем для стохастического"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная классификация - разделяет два класса гиперплоскостью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучение — это явление, при котором полученный при обучении алгоритм показывает на новых данных более низкое качество, чем на обучающей выборке. \\\n",
    "Большие веса в линейных моделях — это симптом переобучения. \\\n",
    "Регуляризация - к функционалу ошибки добавляется слагаемое, которое штрафует за сложность модели (в случае линейной модели — квадрат нормы весов (L2 - регуляризация)\\\n",
    "L1 - регуляризация - позволяет проводить отбор признаков \\\n",
    "Мультиколлинеарность - наличие линейной зависимости между объясняющими переменными (факторами) регрессионной модели\\\n",
    "Коэффициент регуляризации - чем он больше, тем более простая получится модель, чем меньше тем сложнее\\\n",
    "Отложенная выборка - 20-30% выборки для подсчета метрики качества алгоритма \\\n",
    "Крос-валидация - разбиваем выборку на блоки (3, 5, 10). Подходит для маленьких выборок.\n",
    "Гиперпараметры - параметры, которые незьзя настраивать по обучающей выборки (регуляризация, степень полинома)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики качества в регрессии - среднеквадратическая, средняя абсолютная ошибка \\\n",
    "Коэффициент детерминации - доля дисперсии объясненная моделью в общей дисперсии ответов \\\n",
    "Квантильная ошибка - подходит в случае несимметричных потерь, когда например мы сильнее штрафуем за недопрогноз, чем перепрогноз. \\\n",
    "Точность precision = ТР / (TP + FP) \\\n",
    "Полнота recall = TP / (TP + FN) \\\n",
    "F-мера = 2 * precision * recall / (precision + recall)\\\n",
    "AUC-PRC - площадь под PR-кривой - выразительнее в случае дисбаланса классов\\\n",
    "AUC-ROC - площадь под ROC-кривой - не зависит от изменений баланса классов и лучше интерпритируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
